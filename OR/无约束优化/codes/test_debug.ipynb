{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一阶段测试\n",
    "* 主要目的是测试参考代码的可行性和准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x**4\n",
    "x = symbols(\"x\")\n",
    "print(diff(func(x),x))   # 表示将x = 2，带入导函数4*x**3中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WolfePowell(f,d,x,alpha_,rho,sigma):\n",
    "    maxk = 1000  #迭代上限\n",
    "    k = 0\n",
    "    phi0 = fun(x) # fun(x)\n",
    "    dimensions = dim(f) # f_\n",
    "\n",
    "    dx = []\n",
    "    grad = []\n",
    "    item={}\n",
    "    for i in range(dimensions):\n",
    "        item[x_[i]] = x[i]    \n",
    "    for a in range(dimensions):\n",
    "        dx.append(diff(f, symbols('x'+str(a),real=True))) #求偏导\n",
    "\n",
    "        grad.append(dx[a].subs(item)) #求梯度\n",
    "        \n",
    "    phi0_ = np.dot(grad,d)\n",
    "    print(dx)\n",
    "    print(grad)\n",
    "    \n",
    "    a1 = 0\n",
    "    a2 = alpha_\n",
    "    alpha = (a1+a2)/2\n",
    "    phi1 = phi0\n",
    "    phi1_ = phi0_\n",
    "\n",
    "    k = 0\n",
    "    for k in range(maxk):    #限制迭代上限,避免时间太长\n",
    "        phi = fun(x + alpha * d) #fun\n",
    "        if phi <= phi1 + rho * alpha * phi1_:\n",
    "            newx = x + alpha * d\n",
    "            newdx = []\n",
    "            newgrad = []\n",
    "            for a in range(dimensions):\n",
    "                newdx.append(diff(f, symbols('x'+str(a),real=True)))  # 求偏导\n",
    "                newitem={}\n",
    "                for i in range(dimensions):\n",
    "                    newitem[x_[i]] = newx[i]\n",
    "                newgrad.append(newdx[a].subs(newitem)) #求梯度\n",
    "\n",
    "            phi_ = np.dot(newgrad,d)\n",
    "            \n",
    "            if phi_ >= sigma*phi0_:\n",
    "                break\n",
    "            else:\n",
    "                alpha_new = alpha + (alpha-a1) *phi_ / (phi1_-phi_)\n",
    "                a1 = alpha\n",
    "                alpha = alpha_new\n",
    "                phi1 = phi\n",
    "                phi1_ = phi_\n",
    "        else:\n",
    "            alpha_new = a1 + 0.5*(a1-alpha)**2*phi1_/((phi1-phi)-(a1-alpha)*phi1_)\n",
    "            a2 = alpha\n",
    "            alpha = alpha_new\n",
    "    k = k + 1\n",
    "    return alpha\n",
    "\n",
    "'''利用正则表达式统计目标函数维度'''\n",
    "def dim(f_):\n",
    "    dimension_set = []\n",
    "    dimension_set = re.findall(r'x[0-9]\\d*',str(f_))\n",
    "    dimensions = len(set(dimension_set))\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''测试'''\n",
    "x_ = []\n",
    "for a in range(10):\n",
    "    x_.append(symbols('x'+str(a),real=True))  #设置符号变量\n",
    "   \n",
    "def fun(x):\n",
    "    return 100*(x[1]-x[0]**2)**2+(1-x[0])**2  #目标函数\n",
    "f_ = fun(x_)   #用于W-P\n",
    "\n",
    "alpha_ = 1  #alpha_max\n",
    "rho = 0.25  # rho∈（0,1/2） \n",
    "sigma = 0.5  # sigma∈（rho，1）\n",
    "x = np.random.rand(dim(f_))   #随机的初始点\n",
    "d = np.array([-1,-1])     #初始方向\n",
    "\n",
    "alpha=WolfePowell(f_,d,x,alpha_,rho,sigma)\n",
    "print(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(f_, symbols('x'+str(0),real=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二阶段测试\n",
    "* 测试对象为打包好的非精确一维搜索类\n",
    "* 该编自参考代码 https://blog.csdn.net/weixin_43761124/article/details/107436454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import *\n",
    "def fun(x):\n",
    "    return 100*(x[1]-x[0]**2)**2+(1-x[0])**2  #目标函数\n",
    "\n",
    "searcher = Line_Searcher()\n",
    "searcher.add_fun(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import _grad\n",
    "_grad(fun, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2])\n",
    "d = np.array([-1,-1])     #初始方向\n",
    "searcher.WolfePowell(x,np.array([4,-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun([1,2]) - fun([1,2]+0.087*np.array([4,-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三阶段测试\n",
    "* 解析法求梯度的算法扩展到求Hesse阵\n",
    "* 无约束优化：牛顿法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import _dim\n",
    "def _hesse(f, x):\n",
    "    x_ = []\n",
    "    for a in range(10):\n",
    "        x_.append(symbols('x'+str(a),real=True))  #设置符号变量\n",
    "    f_ = f(x_)   # f的正则表达式f_\n",
    "    dimensions = _dim(f_)\n",
    "    \n",
    "    item={}\n",
    "    for i in range(dimensions):\n",
    "        item[x_[i]] = x[i]\n",
    "\n",
    "    dx = []\n",
    "    grad = []\n",
    "    for a in range(dimensions):\n",
    "        dx.append(diff(f_, symbols('x'+str(a),real=True))) #求偏导\n",
    "        grad.append(dx[a].subs(item)) #求梯度 \n",
    "    #print(f_)\n",
    "    print(type(grad[0]))\n",
    "\n",
    "    hesse = []\n",
    "    for i in range(dimensions):\n",
    "        ddx_i = []\n",
    "        hesse_i = []\n",
    "        for j in range(dimensions):\n",
    "            ddx_i.append(diff(dx[i], symbols('x'+str(j),real=True)))\n",
    "            #print(dx[i],'e',ddx_i[j])\n",
    "            hesse_i.append(ddx_i[j].subs(item))\n",
    "        hesse.append(hesse_i)\n",
    "    print(hesse)\n",
    "    return hesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return 100*(x[1]-x[0]**2)**2+(1-x[0])**2 #+sin(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import _grad\n",
    "#_grad(fun, [1,2])\n",
    "h =  _hesse(fun, [1,2])\n",
    "h = [list(map(float, e)) for e in h]\n",
    "#list(map(float,h[0]))\n",
    "np.linalg.inv(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv([[402, -400], [-400, 200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm([1], np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四阶段测试\n",
    "* 正式测试：牛顿法+非精确一维搜索 无约束最优化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newton import opt\n",
    "from sympy import *\n",
    "\n",
    "def fun(x):\n",
    "    return 100*((x[1]-x[0]**2)**2+(x[2]-x[1]**2)**2)+((1-x[0])**2)+sin(x[0])#+(1-x[1])**2)\n",
    "def fun2(x):\n",
    "    return 100*((x[1]-x[0]**2)**2+(x[2]-x[1]**2)**2)+((1-x[0])**2+(1-x[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opter = opt(0.3,0.6)\n",
    "opter.add_fun(fun2)\n",
    "\n",
    "x=[0,0,0]\n",
    "x_min = opter.opt_newtown(x)\n",
    "\n",
    "print(x_min)\n",
    "print(fun2(x_min)-fun2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opter = opt(0.2,0.9)\n",
    "opter.add_fun(fun)\n",
    "\n",
    "x = [0,0,0]\n",
    "x_min = opter.opt_newtown(x)\n",
    "print(x_min)\n",
    "print(fun(x_min)-fun(x))\n",
    "print(float(fun(x_min)-fun([1,1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opter = opt(0.3,0.6)\n",
    "opter.add_fun(fun)\n",
    "\n",
    "x=[0,0,0]\n",
    "x_min=opter.opt_newtown(x)\n",
    "print(x_min)\n",
    "print(fun(x_min)-fun(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 额外测试（捞一下同学）\n",
    "* 拟牛顿方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "触发停机条件：梯度小于阈值，运行正常\n",
      "[1.00000000001488 1.00000000002957]\n"
     ]
    }
   ],
   "source": [
    "from newton import opt\n",
    "from sympy import *\n",
    "\n",
    "def fun(x):\n",
    "    return 100*((x[1]-x[0]**2)**2)+((1-x[0])**2+(1-x[1])**2) #+ sin(x[0])\n",
    "\n",
    "opter = opt(0.2,0.6)\n",
    "opter.add_fun(fun)\n",
    "\n",
    "x0 = [2.1,0.3]\n",
    "x_min = opter.opt_dfp(x0)\n",
    "print(x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很遗憾，目前还不能使用，拟牛顿算法似乎不太稳定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.21958450740902, -1.21958450740894]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search import _grad\n",
    "\n",
    "_grad(fun, [0.892326896222099,0.792227096222099])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.array([1,3])\n",
    "print(np.dot(y.T, y))\n",
    "print(np.dot(y, y.T))\n",
    "print(y.T@y)\n",
    "print(y@y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "坏了，好像是dot的问题\n",
    "看来要把原函数中的一维数组reshape一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_dfp(f, x0, max_iter=1000, delta=1e-10, rho=0.3, sigma=0.6):\n",
    "    ''' 用拟牛顿法+非精确一维搜索完成无约束最优化 '''\n",
    "    searcher = Line_Searcher(rho, sigma)\n",
    "    searcher.add_fun(f)\n",
    "\n",
    "    x = x0\n",
    "    d = np.array([-float(e) for e in _grad(f, x)])\n",
    "    H = np.eye(len(x)) # H0 = I\n",
    "    stop = 0  # 停机条件 0:达到最大迭代次数\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        alpha = searcher.WolfePowell(x, d, 1.)\n",
    "        x_new = x + alpha * d\n",
    "            \n",
    "        if np.linalg.norm(_grad(f, x_new), np.inf) < delta: #np.linalg.norm(np.array([float(e) for e in x_new-x])) < delta:\n",
    "            '''修改停机条件'''\n",
    "            stop = 1 # 停机条件 1:梯度阻尼\n",
    "            break\n",
    "        s = (x_new - x).reshape(len(x),1)\n",
    "        y = (_grad(f, x_new) - np.array([float(e) for e in _grad(f, x)])).reshape(len(x),1)\n",
    "        #print(np.dot(y, y.T))\n",
    "        H = H - np.dot(np.dot(H, np.dot(y, y.T)), H) / np.dot(np.dot(y.T, H), y) + np.dot(s, s.T) / np.dot(s.T, y)\n",
    "        d = -np.dot(H, _grad(f, x_new)) # 搜索方向\n",
    "        x = x_new\n",
    "        \n",
    "    if stop == 0:\n",
    "        print(\"触发停机条件：达到最大迭代次数，注意此时可能未找到最优解，\", end='')\n",
    "        print(\"请增加迭代次数或增大梯度阈值重试。\")\n",
    "    elif stop == 1:\n",
    "       print(\"触发停机条件：梯度小于阈值，运行正常\")        \n",
    "        \n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
