{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real world, you cannot learn how the data was generated. So do not rely on this function when coding your lab.\n",
    "def generate_data(dim, num):\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x, y, mr = generate_data(5, 100)\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMO method\n",
    "import time as t\n",
    "class SVM1:\n",
    "    def __init__(self, dim, tol = 1e-3, C=1.0):\n",
    "        \"\"\"\"\"\"\n",
    "        self.dim = dim\n",
    "        self.w = np.zeros((1,dim))\n",
    "        self.b = 0.0#1.0\n",
    "        self.tol = tol\n",
    "        self.C = C\n",
    "        self.max_iter = 10 # just for stop in test\n",
    "        self.train_time = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" X is m*dim 's ndarray, y is m ndarray \"\"\"\n",
    "        err_msg = \"The data must be of {}D, but got dimension: {}\".format(self.dim, X.shape[1])\n",
    "        assert X.shape[1] == self.dim, err_msg\n",
    "        start = t.time()\n",
    "        #cost = []\n",
    "\n",
    "        #y = np.mat(y)   # m*1 ndarray\n",
    "        alpha = np.zeros((X.shape[0], 1))\n",
    "        iter = 0\n",
    "        while(iter < self.max_iter):\n",
    "            #a1 = self.check_KKT(X, y, alpha) #self.get_alpha1()\n",
    "            for a1 in range(X.shape[0]):\n",
    "                e1 = self.get_err(X, y, a1, self.b, alpha)\n",
    "                if((y[a1]*e1 < -self.tol) and (alpha[a1]<self.C)) or \\\n",
    "                    ((y[a1]*e1 > self.tol) and (alpha[a1]>0)):\n",
    "                    a2 = self.get_alpha2_2(X.shape[0], a1)\n",
    "                    #a2 = self.get_alpha2_1(X, y, a1)\n",
    "                    tmp_a1 = alpha[a1][0]\n",
    "                    tmp_a2 = alpha[a2][0]\n",
    "\n",
    "                    # 优化问题矩形可行域\n",
    "                    if(y[a1]!=y[a2]):\n",
    "                        L = max(0.0, alpha[a2] - alpha[a1])\n",
    "                        U = min(self.C, self.C + alpha[a2] - alpha[a1])# 1自定义\n",
    "                    else:\n",
    "                        L = max(0.0, alpha[a2] + alpha[a1] -self.C)\n",
    "                        U = min(self.C, alpha[a2] + alpha[a1])\n",
    "                    if(L==U):\n",
    "                        continue\n",
    "\n",
    "                    # 提前做一些运算，可以省去大量矩阵计算\n",
    "                    e2 = self.get_err(X, y, a2, self.b, alpha)\n",
    "                    K11 = np.dot(X[a1], X[a1].T)\n",
    "                    K12 = np.dot(X[a1], X[a2].T)\n",
    "                    K22 = np.dot(X[a2], X[a2].T)\n",
    "                    \n",
    "                    A = K11 + K22 - 2*K12\n",
    "                    if(A<0):\n",
    "                        print(\"err\")\n",
    "                        continue\n",
    "                    alpha[a2][0] = tmp_a2 + y[a2] * (e1 - e2) / A\n",
    "                    if(alpha[a2] > U):\n",
    "                        alpha[a2] = U                   \n",
    "                    if(alpha[a2] < L):\n",
    "                        alpha[a2] = L\n",
    "                    alpha[a1][0] = tmp_a1 - y[a1]*y[a2]*(alpha[a2] - tmp_a2)\n",
    "\n",
    "                    #alpha = self.update(X, y, alpha, a1, a2 ,tmp_1, tmp_2) # update alpha, w and b\n",
    "                    b1 = self.b - e1 + y[a1] * (tmp_a1 - alpha[a1]) * K11 + y[a2] * (tmp_a2 - alpha[a2]) * K12\n",
    "                    b2 = self.b - e2 + y[a1] * (tmp_a1 - alpha[a1]) * K12 + y[a2] * (tmp_a2 - alpha[a2]) * K22\n",
    "                    if (0 < alpha[a1]) and (alpha[a1] < self.C):\n",
    "                        self.b = b1\n",
    "                    elif (0 < alpha[a1]) and (alpha[a1] < self.C):\n",
    "                        self.b = b2\n",
    "                    else:\n",
    "                        self.b = (b1 + b2) / 2\n",
    "\n",
    "                    #alpha[alpha<1e-5] = 0\n",
    "                    self.w = np.dot((y * alpha).T, X)     \n",
    "                    #cost.append(self.cost_func(X, y, self.w, self.b))\n",
    "            iter += 1      \n",
    "        \n",
    "        end = t.time()\n",
    "        self.train_time = end - start\n",
    "        return  alpha#, cost\n",
    "\n",
    "    #absorbed    \n",
    "    def get_alpha2_1(self, X, y, a):\n",
    "        y_hat = self.predict(X)\n",
    "        Err = y - y_hat #debug\n",
    "        Err2a = np.absolute(Err - Err[a])\n",
    "        \n",
    "        if((Err2a > self.tol).any()):\n",
    "            return np.argmax(Err2a)\n",
    "        else: #偷个懒\n",
    "            if(a < 1):\n",
    "                return 1\n",
    "            return np.random.randint(0,a)\n",
    "    \n",
    "    def get_alpha2_2(self, n, a):\n",
    "        b = np.random.randint(n)\n",
    "        while(b==a):\n",
    "            b = np.random.randint(n)\n",
    "        return b\n",
    "    #absorbed\n",
    "    def get_alpha2_3(self, X, y, a):\n",
    "        '''选取距离a较远且alpha[a]!=0的点'''\n",
    "\n",
    "    def get_err(self, X, y, i, b, alphas):\n",
    "        \"\"\"返回X的第a条数据的预测偏差\"\"\"\n",
    "        err = np.dot(np.dot((y*alphas).T, X), X[i].T) + b - y[i]\n",
    "        #print(err)\n",
    "        return err\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to generate prediction probabilities on a new\n",
    "        collection of data points.\n",
    "        X is n*dim 's array\n",
    "        \"\"\"\n",
    "        y_hat = np.dot(X, self.w.T) + self.b\n",
    "        y_hat[y_hat>0] = 1.0#\n",
    "        y_hat[y_hat<0] = -1.0#\n",
    "        return y_hat\n",
    "\n",
    "    def cost(self, X, y, w, b):\n",
    "        \"\"\"The cost function\"\"\"\n",
    "        result = 0\n",
    "        y_hat = -(np.dot(X, w.T) + b) + 1\n",
    "        y_hat[y_hat<0] = 0\n",
    "        result = sum(y_hat)/X.shape[0]\n",
    "        result = self.C * result + (np.linalg.norm(w) ** 2) / 2\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD/ mini-batch\n",
    "import time as t\n",
    "class SVM2:\n",
    "    def __init__(self, dim, C=10, lamda=1, max_iter=10):\n",
    "        \"\"\"\n",
    "        You can add some other parameters, which I think is not necessary\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.C = C\n",
    "        self.lamda = lamda\n",
    "        self.max_iter = max_iter\n",
    "        self.w = np.zeros((1, dim))\n",
    "        self.b = 0\n",
    "\n",
    "    def fit(self, X, y, lr=1e-4, tol=1e-4):\n",
    "        \"\"\"\n",
    "        Fit the coefficients via your methods\n",
    "        \"\"\"\n",
    "        w = np.zeros((1, self.dim))\n",
    "        b=0\n",
    "        #cost = []\n",
    "        start = t.time()\n",
    "\n",
    "        #arr = [i for i in range(X.shape[0])]\n",
    "        for j in range(self.max_iter):\n",
    "            arr=np.array([i for i in range(X.shape[0])])\n",
    "            np.random.shuffle(arr)\n",
    "            for i in arr:\n",
    "                if y[i] * (X[i].dot(w.T)) >= 1:\n",
    "                    gradient = 0\n",
    "                    grad_b = 0\n",
    "                else :\n",
    "                    gradient = -y[i] * X[i]\n",
    "                    grad_b = -y[i]\n",
    "                gradient = w + (self.C * gradient)\n",
    "                grad_b = self.C * grad_b\n",
    "                w = w - lr * gradient\n",
    "                b = b - lr * grad_b\n",
    "                #cost.append(self.cost(X, y, w, b))\n",
    "\n",
    "            if np.linalg.norm(lr * gradient) < tol:\n",
    "                break\n",
    "            #arr = np.random.shuffle(arr)\n",
    "            #if(np.linalg.norm(lr * grad) < tol):\n",
    "            #    break        \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "        end = t.time()\n",
    "        self.train_time = end - start\n",
    "        return #cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to generate prediction probabilities on a new\n",
    "        collection of data points.\n",
    "        X is n*dim 's array\n",
    "        \"\"\"\n",
    "        y_hat = np.dot(X, self.w.T) + self.b\n",
    "        y_hat[y_hat>0] = 1.0#\n",
    "        y_hat[y_hat<-0] = -1.0#\n",
    "        return y_hat\n",
    "\n",
    "    def cost(self, X, y, w, b):\n",
    "        \"\"\"The cost function\"\"\"\n",
    "        result = 0\n",
    "        y_hat = -(np.dot(X, w.T) + b) + 1\n",
    "        y_hat[y_hat<0] = 0\n",
    "        result = sum(y_hat)/X.shape[0]\n",
    "        result = self.C * result + (np.linalg.norm(w) ** 2) / 2\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and train your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "dim = 20\n",
    "size = 30000\n",
    "train_ratio = 0.9\n",
    "X_data, y_data, mislabel = generate_data(dim, size) \n",
    "\n",
    "# split data\n",
    "rows = np.arange(size)\n",
    "train_num = int(size * train_ratio)\n",
    "train_X = X_data[rows[: train_num]]\n",
    "test_X = X_data[rows[train_num:]]\n",
    "train_y = y_data[rows[: train_num]]\n",
    "test_y = y_data[rows[train_num:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrcut model and train (remember record time)\n",
    "model1 = SVM1(dim=dim) \n",
    "alpha = model1.fit(train_X, train_y)\n",
    "\n",
    "y_hat = model1.predict(train_X)\n",
    "print(\"training accuarcy: \",1 - sum(np.absolute(train_y - y_hat))[0]/2/train_num)\n",
    "print(\"training time: \", model1.train_time, \"s\")\n",
    "print(\"支持向量数： \", sum(alpha>1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuarcy:  0.910962962962963\n",
      "training time:  0.20905756950378418 s\n"
     ]
    }
   ],
   "source": [
    "model2 = SVM2(dim=dim) \n",
    "model2.fit(train_X, train_y) #cost = \n",
    "\n",
    "y_hat = model2.predict(train_X)\n",
    "print(\"training accuarcy: \",1 - sum(np.absolute(train_y - y_hat))[0]/2/train_num)\n",
    "print(\"training time: \", model2.train_time, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method one: SMO\n",
    "# make prediction\n",
    "y_pred1 = model1.predict(test_X)\n",
    "\n",
    "# compared with answer\n",
    "TP = sum((test_y + 2*y_pred1) == 3)\n",
    "FN = sum((test_y + 2*y_pred1) == -1)\n",
    "TN = sum((test_y + 2*y_pred1) == -3)\n",
    "FP = sum((test_y + 2*y_pred1) == 1)\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (FP + TP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "print(\"mislabel: \", mislabel, \"accuarcy: \",accuracy, \"precision: \", precision, \"recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mislabel:  0.037766666666666664 accuarcy:  [0.909] precision:  [0.90566038] recall:  [0.91578947]\n"
     ]
    }
   ],
   "source": [
    "# method two: SGD\n",
    "# make prediction\n",
    "y_pred1 = model2.predict(test_X)\n",
    "\n",
    "# compared with answer\n",
    "TP = sum((test_y + 2*y_pred1) == 3)\n",
    "FN = sum((test_y + 2*y_pred1) == -1)\n",
    "TN = sum((test_y + 2*y_pred1) == -3)\n",
    "FP = sum((test_y + 2*y_pred1) == 1)\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (FP + TP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "print(\"mislabel: \", mislabel, \"accuarcy: \",accuracy, \"precision: \", precision, \"recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下不属于Lab2，用于测试```sklearn```的模型验证函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ```metrics``` 下的函数 ```accuracy_score()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(test_y, y_pred1), accuracy_score(train_y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ```sklearn.cross_validation``` 下的 ```train_test_split()```\n",
    "    \n",
    "    ```X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(train_data,train_target,test_size=0.4, random_state=0,stratify=y_train)```\n",
    "    - train_target：所要划分的样本结果\n",
    "    - test_size：样本占比，如果是整数的话就是样本的数量\n",
    "    - random_state：随机数的种子，在需要重复试验的时候，除0以外，相同参数可以保证得到一样的划分。但填0或不填，不会得到重复结果。\n",
    "    - stratify是为了保持split前类的分布。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "dim = 20\n",
    "size = 30000\n",
    "train_ratio = 0.9\n",
    "X_data, y_data, mislabel = generate_data(dim, size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_data, y_data, random_state=0, train_size=0.9,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9043333333333333, 0.9145555555555556)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = SVM2(dim=dim) \n",
    "model2.fit(train_X, train_y, tol=1e-3)\n",
    "y_hat = model2.predict(train_X)\n",
    "y_pred2 = model2.predict(test_X)\n",
    "\n",
    "accuracy_score(test_y, y_pred2), accuracy_score(train_y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ```model_selection.cross_val_score(estimatoe,X)```\n",
    "    - estimator: 分类器\n",
    "    - X：array-like，需要学习的数据，可以是列表或2d数组\n",
    "    - y：array-like，可选的，默认为None，监督学习中样本特征向量的真实目标值\n",
    "    - scoring：string,callable or None,可选的，默认为None。\n",
    "        一个字符or一个scorer可调用对象或函数，须实现scorer(estimator,X,y)\n",
    "    - cv：int，交叉验证生成器或者一个迭代器，可选的，默认为None，决定交叉验证划分策略，cv的可选项有以下几种：\n",
    "        1. None：使用默认的3-fold交叉验证\n",
    "        2. Integer：指定在(Stratified)kfold中使用的“折”的数量\n",
    "        3. 可以用作交叉验证生成器的一个对象\n",
    "        4. 一个能够产生train/test划分的迭代器对象\n",
    "\n",
    "该方法可以自行实现，关键是需要一套完整的评分体系（最好能给多分类结果使用），正确率、准确率、召回率、f1、训练时间等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model2,X_data,y_data) # model2 没有score方法，不要运行该代码块"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
